# @package _global_
defaults:
  - override /model: llama2_7b
  - override /data: ifeval
  - override /decoder: baseline_masked_non_retrieval_head


model:
  configs:
    max_new_tokens: 1280