defaults:
  - base_model_config

name: LLaMA2-7b-chat
model_type: hf
configs:
  model_name_or_path: meta-llama/Llama-2-7b-chat-hf
  max_seq_len: 4096
  system_prompt:
  max_new_tokens: 32
